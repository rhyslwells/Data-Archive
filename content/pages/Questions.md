Insert questions here from [[Filtered Questions|Filtered Questions]].

- [[Model Parameters Tuning]]
#### Question prompts

[[pdoc]]
Documentation made simple. pdoc automatically generates beautiful, modern docs from your codebase. It’s perfect for keeping your projects well-documented without spending hours writing manual guides or configuring your styles.

𝐉𝐮𝐬𝐭𝐟𝐢𝐥𝐞
A command runner that simplifies your workflow. Instead of memorizing long commands, 𝐉𝐮𝐬𝐭𝐟𝐢𝐥𝐞 lets you define simple, reusable commands for common tasks.
related to [[Makefile]]?

𝐩𝐲𝐫𝐢𝐠𝐡𝐭  
A static type checker that’s faster and more accurate than many alternatives. If you’re using type hints (and you should be!), 𝐩𝐲𝐫𝐢𝐠𝐡𝐭 will catch errors before they happen and make your codebase way more robust.
What is the difference between pyright and [[Pydantic]]?

**Machine Learning Questions**  

[[R-squared metric not always a good indicator of model performance in regression  ]]

[[Data Cleansing]]
[[Deleting rows or filling them with the mean is not always best ]]
  
**Natural Language Processing Questions**  

[[Transformer]]
1. Why do transformer-based models like BERT or GPT outperform traditional RNNs in NLP tasks?  
[[Vector Embedding|embedding]]
1. How would you decide between using TF-IDF and Word2Vec for text vectorization?  

[[Transfer Learning]]
1. Why might fine-tuning a pre-trained model like GPT yield better results than training from scratch?  

[[Named Entity Recognition]]
2. Why is named entity recognition (NER) a challenging task, and how would you handle ambiguous entities?  
  
**Statistics Questions**  

[[Central Limit Theorem]]
1. Why is the Central Limit Theorem important for data scientists working with small sample sizes?  

[[Evaluation Metrics]]
1. How would you explain the difference between Type I and Type II errors, and why do both matter?  

[[Multicollinearity]]
1. Why does multicollinearity affect regression models, and how can techniques like PCA help? 

[[Hypothesis testing]]
1. In hypothesis testing, why might a very small p-value still lead to incorrect conclusions?  

 
**Scenario-Based Questions**  

[[Data Streaming]]
1. If you’re working with a streaming dataset, why might batch processing not be suitable, and what alternatives would you consider?  

[[Regularisation]]
1. Your model is performing well on training data but poorly on validation data. Why might regularization not always solve this?  

[[Deep Learning]]
1. A client insists on using deep learning for a small dataset. Why might this backfire, and how would you explain the risks?  



[[Imbalanced Datasets]]
1. You have a perfectly balanced dataset but still experience poor classification accuracy. Why might the class separability be the issue?