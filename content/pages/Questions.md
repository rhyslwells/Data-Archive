#question





In [[Linear Regression]] or polynomial ect you use [[Regularisation]]. Can you do something similar for other classifiers?
Partially answered in [[Model training]].

---

[[Why do we do feature importance]]

[[Why use isolation forest (Random Forests) for outliers detection]]




What does the [[Logistic Regression]] graph tell us, specifically the results?

How to use [[Sklearn Pipiline]]? Give an example with an interesting dataset.

How do you know if a [[Classifier]] has been [[overfitting]]? For example with [[Random Forests]]
A: You can use [[Cross validation]]