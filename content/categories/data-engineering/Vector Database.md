---
aliases: []
category: DE
date modified: 27-09-2025
tags:
- database
---
Vector databases are specialized systems designed to handle and manage [[Vector Embedding]]. As most real-world data is unstructured, such as text, images, and audio, vector databases play a role in organizing and querying this data effectively. Used because data is [[unstructured data]] i.e image

Related to:
- [[FAISS]]
### Key Features

- Vector Embeddings: At the core, vector databases store embeddings generated by machine learning models. These embeddings transform complex data into fixed-size vectors that encapsulate semantic information.
- [[Similarity Search]]: By leveraging the geometric properties of vector spaces, vector databases can quickly identify similar items. This is achieved by measuring distances (e.g., [[Cosine Similarity]], Euclidean distance) between vectors.
- Indexing Methods: Various indexing techniques, such as HNSW (Hierarchical Navigable Small World) graphs, IVF (Inverted File), and PQ (Product Quantization), are employed to optimize [[Search]] speed and accuracy. Allows faster searching.

### Querying Vectors

To query vectors, users typically specify a target vector and a similarity metric. The database then retrieves vectors that are closest to the target, based on the chosen metric. 

### Use Cases
1. Long-term Memory for [[LLM]]: Vector databases can store vast amounts of contextual information, enhancing the memory and retrieval capabilities of large language models (LLMs). Implemented using [[Langchain]].
2. Rank and Recommendation system using nearest neighbours.
3. [[Semantic search]]: Unlike traditional keyword-based search, semantic search understands the context and meaning, providing more relevant results. This is particularly useful in natural language processing (NLP) applications.
4. [[Similarity Search]]: Beyond text, vector databases support similarity searches for multimedia data, enabling applications in image recognition, audio analysis, and video retrieval.
### Related Concepts
- [[Vector Embedding]]: The process of converting data into vector form, capturing its semantic essence. A specific type of vector embedding used in NLP to represent words in a continuous vector space.
- [[Semantic Relationships]]: A search technique that leverages the meaning and context of queries and data to deliver more relevant results.
- [[Cosine Similarity]]
### Options
Several vector database solutions are available, each with unique features and optimizations:
- Pincone: Known for its scalability and ease of integration with machine learning workflows.
- Weaviate: Offers a semantic graph database with built-in vector search capabilities.
- Chroma: Focuses on simplicity and performance for embedding-based applications.
- Redis: Provides vector search capabilities through its modules, suitable for real-time applications.
- Qdrant: Designed for high-performance vector search with a focus on scalability.
- Milvus: An open-source solution optimized for handling large-scale vector data.
- Vespa: Combines vector search with traditional search capabilities, ideal for complex applications.
### Resources

[Vector Databases simply explained! (Embeddings & Indexes)](https://www.youtube.com/watch?v=dN0lsF2cvm4&list=PLcWfeUsAys2kC31F4_ED1JXlkdmu6tlrm)

