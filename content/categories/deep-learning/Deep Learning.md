---
aliases:
- DL
category: DL
date modified: 27-09-2025
tags:
- deep_learning
---
Deep learning is a subset of machine learning that uses neural networks to process large-scale data for tasks like image and speech recognition, natural language processing, and recommendation systems. 
 
 A neural network consists of layers of nodes where each node performs weighted sums of its inputs, applies activation functions like [[Relu]] or sigmoid, and produces an output. 
 
 [[Backpropagation]] is the primary algorithm for training neural networks by minimizing error through [[Gradient Descent]]. Regularization techniques, such as dropout, prevent overfitting. 
 
 Popular frameworks like [[PyTorch]] and [[Tensorflow]] facilitate deep learning model development.

Questions:
- [[What is the role of gradient-based optimization in training deep learning models. ]]
- [[Explain different gradient descent algorithms, their advantages, and limitations.]]

Areas of Deep Learning:
- [[LLM]]
- [[Neural network|Neural Network]]

Follow up questions
 - How does the choice of activation function affect the performance of deep learning models across different tasks?
 - What are the trade-offs between different gradient descent algorithms (e.g., [[Stochastic Gradient Descent|SGD]] vs. Adam) in training neural networks? See [[Optimisation techniques]].

Related Topics
 - [[Transfer Learning]]: Applying pre-trained models to new tasks.

