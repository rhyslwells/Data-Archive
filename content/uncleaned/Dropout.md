Regularisation technique for [[Neural network]]

- **Dropout:** A neural network regularization method that drops units at random during training to prevent over-reliance on specific neurons.

[[Dropout]] 
    is another form of [[Regularisation]] for neural networks, where randomly selected neurons are ignored (dropped out) during training to reduce overfitting.