---
tags:
  - drafting
---
   - Techniques like learning rate schedules or adaptive learning rate methods (e.g., [[Adam Optimizer]]) can dynamically adjust the learning rate during training to improve convergence.
- [[Gradient Descent]]
