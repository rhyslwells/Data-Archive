[[Why do we do feature importance]]
- [[feature importance]]
- help in understanding which features are most influential in making predictions.
- [[Interpretation]]
- Compare between different models [[Model Selection]], to see which features are prefered by the model - to understand the algo better. For example, decision trees might prioritize features differently than linear models or neural networks.
- Shows feature relevance over different models.