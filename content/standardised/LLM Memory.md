---
tags:
  - language_models
  - NLP
aliases:
  - What is LLM memory
  - context
category: 
phase: 
topic: 
filename:
---
Memory in large [[language models]] (LLMs) involves managing context windows to enhance reasoning capabilities without the high costs associated with traditional training methods. The goal of [[LLM Memory]] is to address challenges like "forgetting," where LLMs struggle to retain context across interactions.
## Key Concepts:

Forgetting Context:
Understanding how and why LLMs lose context, especially in multi-turn dialogues, and its impact on response accuracy. Forgetting occurs due to the limitations of fixed context windows, manifesting differently in single-turn (immediate forgetting) versus multi-turn interactions (progressive loss of context).

Prioritization of Context:
Techniques for determining which parts of the context are most relevant and need to be retained, optimizing memory usage.

Time Length of Memory:
Balancing how long memory should be maintained to ensure it remains useful and relevant over time.

Dynamic Memory Management:
Adapting memory structures in real-time to accommodate evolving knowledge and interactions.

In-Context Memory:
Memory tied to specific interactions, making it more relevant and easier to apply in particular scenarios.

Multi-turn Interactions:
Addressing context retention across multiple interactions, emphasizing the importance of maintaining coherence over extended conversations.
## Types of Memory:

Semantic Memory:
Focuses on the meaning and [[Semantic Relationships]] between concepts, which is crucial for improving LLM reasoning and context understanding.

Hierarchical Memory:
Balances immediate retrieval with long-term storage of information, enabling better performance in various applications.
Supports evolving and persistent memory systems tailored to specific tasks.