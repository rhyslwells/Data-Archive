---
tags: 
aliases:
  - What is LLM memory
  - context
category: 
phase: 
topic: 
filename:
---
Memory in large [[language models]] (LLMs) involves managing context windows to enhance reasoning capabilities without the high costs associated with traditional training methods. The goal of [[Memory]] is to address challenges like "forgetting," where LLMs struggle to retain context across interactions.
## Key Concepts:

**Forgetting Context**:

Understanding how and why LLMs lose context, especially in multi-turn dialogues, and its impact on response accuracy. Forgetting occurs due to the limitations of fixed **context windows**, manifesting differently in single-turn (immediate forgetting) versus multi-turn interactions (progressive loss of context).

**Prioritization of Context**:
Techniques for determining which parts of the context are most relevant and need to be retained, optimizing memory usage.

**Time Length of Memory**:
Balancing how long memory should be maintained to ensure it remains useful and relevant over time.

**Dynamic Memory Management**:
Adapting memory structures in real-time to accommodate evolving knowledge and interactions.

**In-Context Memory**:
Memory tied to specific interactions, making it more relevant and easier to apply in particular scenarios.

**Multi-turn Interactions**:
Addressing context retention across multiple interactions, emphasizing the importance of maintaining coherence over extended conversations.
## Types of Memory:

**Semantic Memory**:
Focuses on the meaning and [[Semantic Relationships]] between concepts, which is crucial for improving LLM reasoning and context understanding.

**Hierarchical Memory**:
Balances immediate retrieval with long-term storage of information, enabling better performance in various applications.

Supports evolving and persistent memory systems tailored to specific tasks.