---
aliases: [DL]
category: ML
date modified: 27-07-2025
tags: [deep_learning]
title: Deep Learning Overview
---
 Deep learning is a subset of machine learning that uses neural networks to process large-scale data for tasks like image and speech recognition, natural language processing, and recommendation systems. 
 
 A neural network consists of layers of nodes where each node performs weighted sums of its inputs, applies activation functions like ReLU or sigmoid, and produces an output. 
 
 [[Backpropagation]] is the primary algorithm for training neural networks by minimizing error through [[Gradient Descent]]. Regularization techniques, such as dropout, prevent overfitting. 
 
 Popular frameworks like [[PyTorch]] and [[TensorFlow]] facilitate deep learning model development.

Questions:
- [[What is the role of gradient-based optimization in training deep learning models. ]]
- [[Explain different gradient descent algorithms, their advantages, and limitations.]]

Areas of Deep Learning:
- [[LLM]]
- [[Neural network|Neural Network]]


[!Follow up questions]
 - How does the choice of activation function affect the performance of deep learning models across different tasks?
 - What are the trade-offs between different gradient descent algorithms (e.g., [[Stochastic Gradient Descent|SGD]] vs. Adam) in training neural networks? See [[Optimisation techniques]].

[!Related Topics]
 - [[Transfer Learning]]: Applying pre-trained models to new tasks.

