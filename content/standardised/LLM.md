---
title: 
tags:
  - language_models
aliases:
  - LLMs
category:
---
A Large Language Model (LLM) is a type of language model designed for language understanding and generation. They can perform a variety of tasks, including:

- Text generation
- Machine translation
- Summary writing
- Image generation from text
- Machine coding
- Chatbots or Conversational AI

## How do Large Language Models (LLMs) Work?

Large Language Models (LLMs) are a type of artificial intelligence model that is designed to understand and generate human language. Key aspects of how they work include:

- Word Vectors: LLMs represent words as long lists of numbers, known as word vectors.
- Neural Network Architecture: They are built on a neural network architecture known as the [[Transformer]]. This architecture enables the model to identify relationships between words in a sentence, irrespective of their position in the sequence.
- [[Transfer Learning]]: LLMs are trained using a technique known as transfer learning, where a pre-trained model is adapted to a specific task.

## Characteristics of LLMs

- Non-Deterministic: LLMs are non-deterministic, meaning the types of problems they can be applied to are of a probabilistic nature.
- Data Dependency: The performance and behavior of LLMs are heavily influenced by the data they are trained on.