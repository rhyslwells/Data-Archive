---
title: 
tags:
  - drafting
aliases: 
category:
---
[[Recurrent Neural Networks|RNN]]



[[vanishing and exploding gradients problem]]
In standard RNNs, the difficulty lies in retaining useful information over long sequences due to the exponential decrease in the gradient values, which results in poor learning of long-term dependencies.